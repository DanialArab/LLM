{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Tell me how to train my dog to sit. I have a 10 month old puppy and I want to train him to sit. I have tried the treat method and he just sits there and looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks\n"
     ]
    }
   ],
   "source": [
    "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")\n",
    "\n",
    "print(non_finetuned_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I think it's a great planet.\n",
      "I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think it's a great planet. I think\n"
     ]
    }
   ],
   "source": [
    "print(non_finetuned(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm not sure if I've ever mentioned this before, but I'm a huge Taylor Swift fan. I've been a fan since her first album, and I've been a fan ever since. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I've been a fan of her music, her lyrics, her style, her personality, and her personality. I'\n"
     ]
    }
   ],
   "source": [
    "print(non_finetuned(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry to hear that. I'll look into it.\n",
      "Customer: I'm not sure if I got the right blanket.\n",
      "Agent: I'm sorry to hear that. I'll look into it.\n",
      "Customer: I'm not sure if I got the right blanket. I'm not sure if I got the right blanket.\n",
      "Agent: I'm sorry to hear that. I'll look into it. I'll look into it.\n",
      "Customer: I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket.\n",
      "Agent: I'm sorry to hear that. I'll look into it. I'll look into it. I'll look into it.\n",
      "Customer: I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blank\n"
     ]
    }
   ],
   "source": [
    "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on command.\n",
      "Training a dog to sit on command is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit on command:\n",
      "\n",
      "1. Choose a quiet and distraction-free area: Find a quiet area with minimal distractions where your dog can focus on you.\n",
      "2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n",
      "3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n",
      "4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n",
      "5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n",
      "6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")\n",
    "\n",
    "print(finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training your dog to sit is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit:\n",
      "\n",
      "1. Choose a quiet and distraction-free area: Find a quiet area with no distractions where your dog can focus on you.\n",
      "2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n",
      "3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n",
      "4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n",
      "5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n",
      "6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with the action of sitting down.\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mars is a fascinating planet that has captured the imagination of humans for centuries. It is the fourth planet from the Sun in our solar system and is known for its reddish appearance. Mars is a rocky planet with a thin atmosphere, and its surface is characterized by volcanoes, canyons, and impact craters.\n",
      "\n",
      "One of the most intriguing aspects of Mars is its potential to support life. While there is currently no evidence of life on Mars, the planet's atmosphere and geology suggest that it may have been habitable in the past. NASA's Curiosity rover has been exploring Mars since 2012, and it has discovered evidence of water on the planet, which is a key ingredient for life.\n",
      "\n",
      "Mars is also a popular target for space missions and future human settlements. Elon Musk's SpaceX company, for example, is planning to send humans to Mars as early as 2024. The potential for Mars to become a human settlement is exciting, but it also raises many challenges and questions, such as how to protect the planet's atmosphere and how to sustain a human population on a\n"
     ]
    }
   ],
   "source": [
    "print(finetuned_model(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Taylor Swift's best friend is a person who has been by her side through thick and thin. Here are some possible candidates:\n",
      "\n",
      "1. Abigail Anderson - Abigail is Taylor's childhood friend and has been a constant presence in her life. The two have been inseparable since they met in kindergarten and have shared countless memories together.\n",
      "2. Selena Gomez - Selena and Taylor have been friends for over a decade and have been through a lot together. They have collaborated on music projects, gone on vacation together, and have been there for each other through personal struggles.\n",
      "3. Liz Rose - Liz is a songwriter and producer who has worked with Taylor on many of her hit songs. The two have a close professional relationship and have also become close friends over the years.\n",
      "4. Joe Jonas - Joe and Taylor were in a relationship for a few years in the early 2000s and have remained close friends since then. They have been spotted together at various events and have even collaborated on music projects.\n",
      "5. Ed Sheeran - Ed and Taylor have been friends for several years and have collaborated on several\n"
     ]
    }
   ],
   "source": [
    "print(finetuned_model(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UserError",
     "evalue": "Currently this user has support for base models: ['hf-internal-testing/tiny-random-gpt2', 'EleutherAI/pythia-70m', 'EleutherAI/pythia-70m-deduped', 'EleutherAI/pythia-70m-v0', 'EleutherAI/pythia-70m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-70m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-70m-v1', 'EleutherAI/neox-ckpt-pythia-70m-deduped-v1', 'EleutherAI/gpt-neo-125m', 'EleutherAI/pythia-160m', 'EleutherAI/pythia-160m-deduped', 'EleutherAI/pythia-160m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-70m', 'EleutherAI/neox-ckpt-pythia-160m', 'EleutherAI/neox-ckpt-pythia-160m-deduped-v1', 'EleutherAI/pythia-2.8b', 'EleutherAI/pythia-410m', 'EleutherAI/pythia-410m-v0', 'EleutherAI/pythia-410m-deduped', 'EleutherAI/pythia-410m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-410m', 'EleutherAI/neox-ckpt-pythia-410m-deduped-v1', 'cerebras/Cerebras-GPT-111M', 'cerebras/Cerebras-GPT-256M', 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-70b-chat-hf', 'Intel/neural-chat-7b-v3-1']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama/program/util/run_ai.py:45\u001b[0m, in \u001b[0;36mmake_web_request\u001b[0;34m(http_method, url, api_key, json)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     resp\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.lamini.ai/v2/lamini/completions",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUserError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/danial/fine_tuning_llm/1.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/danial/fine_tuning_llm/1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m chatgpt \u001b[39m=\u001b[39m BasicModelRunner(\u001b[39m\"\u001b[39m\u001b[39mchat-gpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/danial/fine_tuning_llm/1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(chatgpt(\u001b[39m\"\u001b[39;49m\u001b[39mTell me how to train my dog to sit\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama/runners/runner.py:16\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     18\u001b[0m input_groups \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_into_groups(inputs, num_jobs_per_server)\n\u001b[1;32m     20\u001b[0m \u001b[39mwith\u001b[39;00m cf\u001b[39m.\u001b[39mThreadPoolExecutor(max_workers\u001b[39m=\u001b[39mnum_servers) \u001b[39mas\u001b[39;00m executor:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama/runners/basic_model_runner.py:52\u001b[0m, in \u001b[0;36mBasicModelRunner.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39m# Singleton\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     input_objects \u001b[39m=\u001b[39m Input(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39minputs)\n\u001b[0;32m---> 52\u001b[0m output_objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm(\n\u001b[1;32m     53\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49minput_objects,\n\u001b[1;32m     54\u001b[0m     output_type\u001b[39m=\u001b[39;49mOutput,\n\u001b[1;32m     55\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     56\u001b[0m     enable_peft\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_peft,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output_objects, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     59\u001b[0m     outputs \u001b[39m=\u001b[39m [o\u001b[39m.\u001b[39moutput \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m output_objects]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama/engine/typed_lamini.py:13\u001b[0m, in \u001b[0;36mTypedLamini.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 13\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     15\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39moutput_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama/engine/lamini.py:113\u001b[0m, in \u001b[0;36mLamini.__call__\u001b[0;34m(self, input, output_type, stop_tokens, model_name, enable_peft, random, max_tokens, streaming)\u001b[0m\n\u001b[1;32m    100\u001b[0m req_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_llm_req_map(\n\u001b[1;32m    101\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid,\n\u001b[1;32m    102\u001b[0m     model_name \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     streaming,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcompletions\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m make_web_request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_key, req_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama/program/util/run_ai.py:70\u001b[0m, in \u001b[0;36mmake_web_request\u001b[0;34m(http_method, url, api_key, json)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         json_response \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m UserError(json_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUserError\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m503\u001b[39m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mUserError\u001b[0m: Currently this user has support for base models: ['hf-internal-testing/tiny-random-gpt2', 'EleutherAI/pythia-70m', 'EleutherAI/pythia-70m-deduped', 'EleutherAI/pythia-70m-v0', 'EleutherAI/pythia-70m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-70m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-70m-v1', 'EleutherAI/neox-ckpt-pythia-70m-deduped-v1', 'EleutherAI/gpt-neo-125m', 'EleutherAI/pythia-160m', 'EleutherAI/pythia-160m-deduped', 'EleutherAI/pythia-160m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-70m', 'EleutherAI/neox-ckpt-pythia-160m', 'EleutherAI/neox-ckpt-pythia-160m-deduped-v1', 'EleutherAI/pythia-2.8b', 'EleutherAI/pythia-410m', 'EleutherAI/pythia-410m-v0', 'EleutherAI/pythia-410m-deduped', 'EleutherAI/pythia-410m-deduped-v0', 'EleutherAI/neox-ckpt-pythia-410m', 'EleutherAI/neox-ckpt-pythia-410m-deduped-v1', 'cerebras/Cerebras-GPT-111M', 'cerebras/Cerebras-GPT-256M', 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-70b-chat-hf', 'Intel/neural-chat-7b-v3-1']"
     ]
    }
   ],
   "source": [
    "chatgpt = BasicModelRunner(\"chat-gpt\")\n",
    "\n",
    "print(chatgpt(\"Tell me how to train my dog to sit\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
